{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd9c202-a59f-4c53-b5f5-37f9e783fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67e3ce03-d75b-4ca9-b38e-befba1fd1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class Task1Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8db6babe-3fa2-4cfc-8854-9f1283f1fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1ModelAAIndex(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_1 = nn.Linear(n, 32, dtype=torch.float32)\n",
    "        self.output_layer = nn.Linear(32, 1, dtype=torch.float32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.hidden_layer_1(x))\n",
    "        return self.sigmoid(self.output_layer(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2867aba6-5368-45ca-8141-b5dcfa54561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from protlearn import features, preprocessing, dimreduction\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataset / sequences\n",
    "df = pd.read_csv('/Users/daniel/Desktop/PBL/Task 1/preprocessed/pp_task1_c50_15_70.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8bf7716a-cc41-45e0-bbf2-344eec8d3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(df['Sequence'])\n",
    "X_temp = features.aaindex1(seqs, standardize='minmax')[0]\n",
    "X = torch.tensor(X_temp, dtype=torch.float32)\n",
    "y = torch.tensor(list(df['Enzyme']), dtype=torch.float32).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b4e2c5a0-b049-4293-8bbc-a31a083ef24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "be8bdc93-3c69-47ae-be81-bac42d769f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Task1Dataset(X_train, y_train)\n",
    "#training_dataset_2 = Task1Dataset(X_train_2, y_train_2)\n",
    "#training_dataset_3 = Task1Dataset(X_train_3, y_train_3)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True)\n",
    "#dataloader_2 = DataLoader(dataset=training_dataset_2, batch_size=batch_size, shuffle=True)\n",
    "#dataloader_3 = DataLoader(dataset=training_dataset_3, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b4e16283-a2db-4caf-b1aa-5e69c11e4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "size = 553\n",
    "model = Task1ModelAAIndex(size)\n",
    "#model_2 = Task1ModelAAIndex(size)\n",
    "#model_3 = Task1ModelAAIndex(size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer_2 = optim.SGD(model_2.parameters(), lr=learning_rate)\n",
    "#optimizer_3 = optim.SGD(model_3.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "#criterion_2 = nn.MSELoss()\n",
    "#criterion_3 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b5db4e57-8528-47a3-a0b0-fb2b95fdb1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6722226910859829\n",
      "Training loss: 0.6060492032873868\n",
      "Training loss: 0.5667113862739125\n",
      "Training loss: 0.5563963780022696\n",
      "Training loss: 0.5491042681646675\n",
      "Training loss: 0.5437745191316212\n",
      "Training loss: 0.5408263804191148\n",
      "Training loss: 0.5334319476857823\n",
      "Training loss: 0.5320103638496279\n",
      "Training loss: 0.5303646441128521\n",
      "Training loss: 0.5280710023554014\n",
      "Training loss: 0.5237464707913575\n",
      "Training loss: 0.5216892040948653\n",
      "Training loss: 0.5192839737073272\n",
      "Training loss: 0.5188060810691432\n",
      "Training loss: 0.516621569131018\n",
      "Training loss: 0.5160886719753601\n",
      "Training loss: 0.5157456001828368\n",
      "Training loss: 0.5130863423814821\n",
      "Training loss: 0.5121583214519146\n",
      "Training loss: 0.5117453593668584\n",
      "Training loss: 0.5127835640659868\n",
      "Training loss: 0.5092594914439\n",
      "Training loss: 0.5075748235912866\n",
      "Training loss: 0.5093475280252335\n",
      "Training loss: 0.5072405985214463\n",
      "Training loss: 0.5078503331309782\n",
      "Training loss: 0.5073984875784546\n",
      "Training loss: 0.5070870506158212\n",
      "Training loss: 0.5055416351316231\n",
      "Training loss: 0.5062037711917677\n",
      "Training loss: 0.5068958667168414\n",
      "Training loss: 0.5046024193035663\n",
      "Training loss: 0.5045221507693393\n",
      "Training loss: 0.5047423163820692\n",
      "Training loss: 0.503519016281477\n",
      "Training loss: 0.5035732878347479\n",
      "Training loss: 0.5042029807442113\n",
      "Training loss: 0.5026663945070181\n",
      "Training loss: 0.5041195994219816\n",
      "Training loss: 0.5002361241383736\n",
      "Training loss: 0.502179771168471\n",
      "Training loss: 0.5007895980822191\n",
      "Training loss: 0.5005861184001523\n",
      "Training loss: 0.5017583986540942\n",
      "Training loss: 0.5008504055502779\n",
      "Training loss: 0.49878304062755174\n",
      "Training loss: 0.4998370301486259\n",
      "Training loss: 0.5001786859677985\n",
      "Training loss: 0.49936927067694753\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "train_losses = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for feats, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feats)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / (len(training_dataset) / dataloader.batch_size)\n",
    "    train_losses.append(avg_loss)\n",
    "    print('Training loss: ' + str(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd8aeb-ae40-49e5-9761-9045157dcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_1 = model_1(x_test_1)\n",
    "y_pred_2 = model_2(x_test_2)\n",
    "y_pred_3 = model_3(x_test_3)\n",
    "\n",
    "cm_1 = confusion_matrix(y_test_1, y_pred_1)\n",
    "cm_2 = confusion_matrix(y_test_2, y_pred_2)\n",
    "cm_3 = confusion_matrix(y_test_3, y_pred_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
